---
layout: post
title:  "Задачка на Python...найти оптимальный путь до конца рабочего дня"
date:   2021-03-28 23:30:13 +0300
categories: python
---

## _На днях мне прилетела казалось бы тривиальная задачка, решить которую я попробовал с помощью Python._ 

## Условие:

1. Данные следующего формата. 

|КОЦ	|КОД	|MM	|Year	|НачалоРасчет	|КонецРасчет|
|------|------|------|------|------|------|
|учитель	|1007800385	|2	|2020	|13.02.2020	|29.02.2020|
|щека	            |1001000385	|3	|2020	|01.03.2020	|11.03.2020|
|учитель	|1007800385	|2	|2020	|18.02.2020	|30.02.2020|
|взаимодействие    |1003000388	|5	|2020	|06.05.2020	|12.05.2020|
|фамилия	|1065000385	|6	|2020	|17.06.2020	|23.06.2020|
|краска	|1008700385	|7	|2020	|29.07.2020	|31.07.2020|
|объяснение	|1003200385	|8	|2020	|01.08.2020	|04.08.2020|
|планета	|1022000385	|9	|2019	|18.09.2019	|24.09.2019|
|фамилия	|1065000385	|6	|2020	|21.06.2020	|28.06.2020|

Так как данные были в таблице, не удивительно, что я сразу же подумал о Pandas
Как можно заметить, в данных присутствует некий аналог суррогатного ключа: КОЦ и КОД, номер месяца, год и периоды.
Задача стояла следующим образом:
Найти общее количество дней в указанном периоде для каждого значения КОД (КонецРасчет включительно), т.е. ответ должен быть примерно таким:

|КОЦ	|КОД	|MM	|Year	|НачалоРасчет	|КонецРасчет| Ответ|
|------|------|------|------|------|------|------|
|учитель	|1007800385	|2	|2020	|13.02.2020	|25.02.2020|13|

Но есть один нюанс: судя по данным, у нас бывает несколько записей КОЦ и КОД в рамках одного месяца и года, но с разными периодами. Пример:

|КОЦ	|КОД	|MM	|Year	|НачалоРасчет	|КонецРасчет|
|------|------|------|------|------|------|
|учитель	|1007800385	|2	|2020	|13.02.2020	|25.02.2020|
|учитель	|1007800385	|2	|2020	|18.02.2020	|27.02.2020|

В таком случае, нам нужно учесть пересечение периодов и посчитать только реальное общее количество дней в периоде. Пример ответа (в обе строки прописан один и тот же ответ):

|КОЦ	|КОД	|MM	|Year	|НачалоРасчет	|КонецРасчет| Ответ|
|------|------|------|------|------|------|------|
|учитель	|1007800385	|2	|2020	|13.02.2020	|25.02.2020|15|
|учитель	|1007800385	|2	|2020	|18.02.2020	|27.02.2020|15|

Данных очень много и я "отщипнул" себе кусок в csv на 320 тыс. строк для работы.

```python
#!/usr/bin/env python
# coding: utf-8

import pandas as pd
from datetime import timedelta, date, datetime
import time

# Открываю файл Excel
my_data = pd.read_excel('1.xlsx', index_col=None)

# Параметризируем
RC = 'КОЦ'
XCODE = 'КОД'
MONTH_NUM = 'MM'
YEAR_NUM = 'Year'
BEGIN_DATE = 'НачалоРасчет'
END_DATE = 'КонецРасчет'
DAYS_COUNT = 'days_count'

# Привожу весь XCODE к строке т.к. Pandas ругался на любые дальнейшие операции с данными в столбце из-за их разнородности
my_data[XCODE] = my_data[XCODE].astype(str)

# Создаю новый датафрейм в котором только дубли по RC, XCODE, MONTH_NUM, YEAR_NUM
only_duplicate = my_data[my_data.duplicated(subset=[RC, XCODE, MONTH_NUM, YEAR_NUM], keep=False)]
# Сортирую по столбцам
only_duplicate.sort_values(by=[XCODE, MONTH_NUM, RC])

# Функция сбора дат в периоде
def daterange(start_date, end_date):
    for n in range(int((end_date - start_date).days)):
        yield start_date + timedelta(n)
        
for unique_year in only_duplicate[YEAR_NUM].unique():
    # Создаю датафрейм только с unique_year
    df_with_unique_year = only_duplicate.loc[(only_duplicate[YEAR_NUM] == unique_year)]
    for unique_month in df_with_unique_year[MONTH_NUM].unique():
        # Создаю датафрейм только с unique_month
        df_with_unique_year_and_month = df_with_unique_year.loc[(df_with_unique_year[MONTH_NUM] == unique_month)]
        for unique_xcode in df_with_unique_year_and_month[XCODE].unique():
            # Создаю датафрейм только с unique_xcode
            df_with_unique_xcode = df_with_unique_year_and_month.loc[(df_with_unique_year_and_month[XCODE] == unique_xcode)]
            for unique_rc in df_with_unique_xcode[RC].unique():
                # Создаю датафрейм только с unique_rc
                df_with_unique_rc = df_with_unique_xcode.loc[(df_with_unique_xcode[RC] == unique_rc)]
                # Объявляю списки для индексов (адреса строки) и для дат начала и окончания
                my_indexes = []
                my_unique_dates_period = []
                for index, row in df_with_unique_rc.iterrows():
                    # Записываем индексы строк с которыми работаем, чтоб потом найти их в общем датафрейме
                    my_indexes.append(index)
                    # Получаем все даты в заданном периоде и записываем все даты в список дат
                    for single_date in daterange(start_date, end_date + timedelta(1)):
                        my_unique_dates_period.append(single_date)
                # Находим в общем датафрейме по записанным ранее индексам нужные строки и оставляем в списке с датами только уникальные значения
                # после чего подсчитываем количество элементов списка дат и записываем в столбец DAYS_COUNT
                for indx in my_indexes:
                    my_data.loc[indx, DAYS_COUNT] = len(set(my_unique_dates_period))

# Записываем в строки значения DAYS_COUNT для тех, кто имеет только одну запись простой разницей END_DATE и BEGIN_DATE + 1
my_data[DAYS_COUNT] = my_data[DAYS_COUNT].fillna(((my_data[END_DATE] - my_data[BEGIN_DATE]).dt.days) + 1)
```
В результате задача решена, но встает вопрос оптимальности алгоритма и скорости ее выполнения. При первичном запуске на ноутбуке, время выполнения было около 8,5 минут. При последующих запусках стабильно 5 минут 40 секунд. Я более чем уверен, что Pandas позволяет решать задачу пересечения временных диапазонов более продвинутыми средствами, но пока у меня не дошли до изучения этого вопроса руки. Но надо заметить, что этот результат более преемлемый, чем результат аналогичного скрипта написанного моим коллегой на R и выполнявшегося в Tibco Spotfire - там время выполнения на аналогичном количестве данных приближалось к получасу. Если у вас есть предложение более оптимального алгоритма - пишите мне на почту: <at-pernat@ya.ru> 